{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem:\n",
    "In this year's Halloween playground competition, you're challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:58:47.564083Z",
     "start_time": "2019-02-04T15:58:47.552692Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\c5250435\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from flashtext.keyword import KeywordProcessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "# libraries for dataset preparation, feature engineering, model training \n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "#import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:35.528699Z",
     "start_time": "2019-02-04T16:09:35.434124Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the different values available for the column 'author'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:35.695882Z",
     "start_time": "2019-02-04T16:09:35.684342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:37.872413Z",
     "start_time": "2019-02-04T16:09:37.848419Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function for removing regex\n",
    "def regex_filtering(text):\n",
    "        if text:\n",
    "            #removing all email metadata fix it for email terms only\n",
    "            text=re.sub(r\"^(sender|to|copy|from|sent|subject|date|cc|e|von|datum|an|importance|bcc):.*$\",\" \",text,flags=re.M)\n",
    "            #removing all mail ids\n",
    "            text=re.sub(r\"\\S*@\\S*\\s?\",\" \",text)\n",
    "            #removing all links\n",
    "            text=re.sub(r\"(((https?|ftp|file):\\/\\/)|www\\\\.)\\\\S+\", ' ', text, flags=re.MULTILINE)\n",
    "            text=re.sub(r\"\\w*\\.\\w{1,4}\", '', text, flags=re.MULTILINE)\n",
    "            #removing all non word character\n",
    "            text=re.sub(r\"([^a-zA-Z0-9\\\\u00C0-\\\\u00FF@]|[Ã£Ã¢])+\",' ',text)\n",
    "            #removing words with numbers \n",
    "            text=re.sub(r'\\w*\\d\\w*', ' ', text)\n",
    "            #removing single characters\n",
    "            text=re.sub(r'\\b\\S{1}\\s+',' ',text)\n",
    "            #removing words with repeating characters\n",
    "            text=re.sub(r'\\b(\\w)\\1{1,}\\s+',' ',text)\n",
    "            #removing punkt\n",
    "            text = text.translate(str.maketrans('','',string.punctuation))\n",
    "            #removing extra whitespace\n",
    "            text=re.sub(r\"\\s\\s+\",' ',text)\n",
    "            #removing repeating words\n",
    "            text=re.sub(r\"(\\w+\\s+)\\1{1,}\",' ',text)\n",
    "            #removing whitespaces\n",
    "            text=text.strip()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:38.590202Z",
     "start_time": "2019-02-04T16:09:38.583706Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenize Terms and remove stopwords\n",
    "def tokenize_term(x):\n",
    "        predefined_stopwords='horror perfectly'\n",
    "        english_stopwords=stopwords.words(\"english\")\n",
    "        german_stopwords=stopwords.words(\"german\")\n",
    "        stopwords_list=(list(predefined_stopwords.split(' '))+english_stopwords+german_stopwords)         \n",
    "        keyword_processor_stopwords = KeywordProcessor()\n",
    "        for each in stopwords_list:\n",
    "            keyword_processor_stopwords.add_keyword(each,' ')   \n",
    "        sentence=keyword_processor_stopwords.replace_keywords(x)\n",
    "        return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:38.990639Z",
     "start_time": "2019-02-04T16:09:38.986352Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combined function\n",
    "def preprocess(text):\n",
    "    return regex_filtering(tokenize_term(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll check the preprocessing steps for a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:42.049179Z",
     "start_time": "2019-02-04T16:09:42.033958Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing: This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.\n",
      "\n",
      "After processing: process however afforded means ascertaining dimensions dungeon might make circuit return point whence set without aware fact uniform seemed wall\n"
     ]
    }
   ],
   "source": [
    "x=df['text'][0]\n",
    "print('Before processing: '+x+'\\n')\n",
    "y=preprocess(x)\n",
    "print('After processing: '+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll remove all the null and empty texts from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:09:43.795267Z",
     "start_time": "2019-02-04T16:09:43.766707Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing null/empty records from data, size of dataframe is (19579, 3)\n",
      "After removing null/empty records from data, size of dataframe is (19579, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Before removing null/empty records from data, size of dataframe is {}'.format(df.shape))\n",
    "df=df.loc[~df['text'].isnull()]\n",
    "df=df.loc[df['text']!='']\n",
    "df=df.loc[~df['author'].isnull()]\n",
    "df=df.loc[df['author']!='']\n",
    "print('After removing null/empty records from data, size of dataframe is {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen , there were no text records present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:13:16.981144Z",
     "start_time": "2019-02-04T16:12:38.332406Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>youth passed solitude best years spent gentle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>astronomer perhaps point took refuge suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>surcingle hung ribands body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>knew could say stereotomy without brought thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>confess neither structure languages code gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id16737</td>\n",
       "      <td>He shall find that I can feel my injuries; he ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>shall find feel injuries shall learn dread rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id16607</td>\n",
       "      <td>Here we barricaded ourselves, and, for the pre...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>barricaded present secure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id19764</td>\n",
       "      <td>Herbert West needed fresh bodies because his l...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Herbert West needed fresh bodies life work rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id18886</td>\n",
       "      <td>The farm like grounds extended back very deepl...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>farm like grounds extended back deeply hill al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id17189</td>\n",
       "      <td>But a glance will show the fallacy of this idea.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>glance show fallacy idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id12799</td>\n",
       "      <td>He had escaped me, and I must commence a destr...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>escaped must commence destructive almost endle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id08441</td>\n",
       "      <td>To these speeches they gave, of course, their ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>speeches gave course interpretation fancying d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id13117</td>\n",
       "      <td>Her native sprightliness needed no undue excit...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>native sprightliness needed undue excitement p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id14862</td>\n",
       "      <td>I even went so far as to speak of a slightly h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>even went far speak slightly hectic cough one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id20836</td>\n",
       "      <td>His facial aspect, too, was remarkable for its...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>facial aspect remarkable maturity though share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id11411</td>\n",
       "      <td>Now the net work was not permanently fastened ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>net work permanently fastened hoop attached se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id08075</td>\n",
       "      <td>It was not that the sounds were hideous, for t...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>sounds hideous held vibrations suggesting noth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id18925</td>\n",
       "      <td>On every hand was a wilderness of balconies, o...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>every hand wilderness balconies verandas minar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id19925</td>\n",
       "      <td>With how deep a spirit of wonder and perplexit...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>deep spirit wonder perplexity wont regard remo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id01704</td>\n",
       "      <td>These bizarre attempts at explanation were fol...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>bizarre attempts explanation followed others e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id10125</td>\n",
       "      <td>For many prodigies and signs had taken place, ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>many prodigies signs taken place far wide sea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id02448</td>\n",
       "      <td>All that as yet can fairly be said to be known...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>yet fairly said known Pure gold made readily l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id23451</td>\n",
       "      <td>I seemed to be upon the verge of comprehension...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>seemed upon verge comprehension without power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id27907</td>\n",
       "      <td>Our compasses, depth gauges, and other delicat...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>compasses depth gauges delicate instruments ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id08121</td>\n",
       "      <td>This the young warriors took back with them to...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>young warriors took back Sarnath symbol conque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19549</th>\n",
       "      <td>id20955</td>\n",
       "      <td>But it was not so; I was the same in strength,...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>strength earnest craving sympathy yearning act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19550</th>\n",
       "      <td>id01270</td>\n",
       "      <td>He then took the book himself, and read me a c...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>took book read chapter aloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19551</th>\n",
       "      <td>id22290</td>\n",
       "      <td>\"Adolphe Le Bon, clerk to Mignaud et Fils, dep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>Adolphe Le Bon clerk Mignaud et Fils deposes d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19552</th>\n",
       "      <td>id20272</td>\n",
       "      <td>But of the character of his remarks at the per...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>character remarks periods question example bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19553</th>\n",
       "      <td>id18082</td>\n",
       "      <td>He notes every variation of face as the play p...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>notes every variation face play progresses gat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>id07976</td>\n",
       "      <td>They admitted they had been drunk, but both vo...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>admitted drunk vowed seen crazily dressed trio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>id26741</td>\n",
       "      <td>The rays of the newly risen sun poured in upon...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>rays newly risen sun poured upon whole windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>id26698</td>\n",
       "      <td>To the north on the craggy precipice a few pac...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>north craggy precipice paces verge sprang magn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19557</th>\n",
       "      <td>id22265</td>\n",
       "      <td>The frauds of the banks of course I couldn't h...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>frauds banks course help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>id14778</td>\n",
       "      <td>He was attired, as I had expected, in a costum...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>attired expected costume altogether similar we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>id18823</td>\n",
       "      <td>When a fumbling came in the nearer casements h...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>fumbling came nearer casements crept around we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19560</th>\n",
       "      <td>id00893</td>\n",
       "      <td>But then there is the tone laconic, or curt, w...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>tone laconic curt lately come much use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19561</th>\n",
       "      <td>id08678</td>\n",
       "      <td>Average people in society and business New Eng...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Average people society business New England tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>id10857</td>\n",
       "      <td>The modes and sources of this kind of error ar...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>modes sources kind error well typified contemp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>id10563</td>\n",
       "      <td>Yet from whom has not that rude hand rent away...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>Yet rude hand rent away dear connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>id11752</td>\n",
       "      <td>Almighty God no, no They heard they suspected ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>Almighty God heard suspected knew making mocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>id26214</td>\n",
       "      <td>I hope you have not been so foolish as to take...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>hope foolish take offence little brusquerie mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>id00832</td>\n",
       "      <td>These reflections made our legislators pause, ...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>reflections made legislators pause could decid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19567</th>\n",
       "      <td>id04187</td>\n",
       "      <td>Because there were some considerations of deep...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>considerations deep interest beyond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>id22378</td>\n",
       "      <td>Before going in we walked up the street, turne...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>going walked street turned alley turning passe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>id26790</td>\n",
       "      <td>Once my fancy was soothed with dreams of virtu...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>fancy soothed dreams virtue fame enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>id14263</td>\n",
       "      <td>Nay, you may have met with another whom you ma...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>Nay may met another may love considering bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>id14420</td>\n",
       "      <td>My watch was still going, and told me that the...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>watch still going told hour past noon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>id03325</td>\n",
       "      <td>But these and other difficulties attending res...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>difficulties attending respiration means great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>id07567</td>\n",
       "      <td>Stress of weather drove us up the Adriatic Gul...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>Stress weather drove us Adriatic Gulph vessel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>could fancied looked eminent landscape painter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>lids clenched together spasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>Mais il faut agir say Frenchman never faints o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>item news like strikes us coolly received</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>laid gnarled claw shoulder seemed shaking alto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author  \\\n",
       "0      id26305  This process, however, afforded me no means of...    EAP   \n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "5      id22965  A youth passed in solitude, my best years spen...    MWS   \n",
       "6      id09674  The astronomer, perhaps, at this point, took r...    EAP   \n",
       "7      id13515        The surcingle hung in ribands from my body.    EAP   \n",
       "8      id19322  I knew that you could not say to yourself 'ste...    EAP   \n",
       "9      id00912  I confess that neither the structure of langua...    MWS   \n",
       "10     id16737  He shall find that I can feel my injuries; he ...    MWS   \n",
       "11     id16607  Here we barricaded ourselves, and, for the pre...    EAP   \n",
       "12     id19764  Herbert West needed fresh bodies because his l...    HPL   \n",
       "13     id18886  The farm like grounds extended back very deepl...    HPL   \n",
       "14     id17189   But a glance will show the fallacy of this idea.    EAP   \n",
       "15     id12799  He had escaped me, and I must commence a destr...    MWS   \n",
       "16     id08441  To these speeches they gave, of course, their ...    EAP   \n",
       "17     id13117  Her native sprightliness needed no undue excit...    MWS   \n",
       "18     id14862  I even went so far as to speak of a slightly h...    EAP   \n",
       "19     id20836  His facial aspect, too, was remarkable for its...    HPL   \n",
       "20     id11411  Now the net work was not permanently fastened ...    EAP   \n",
       "21     id08075  It was not that the sounds were hideous, for t...    HPL   \n",
       "22     id18925  On every hand was a wilderness of balconies, o...    EAP   \n",
       "23     id19925  With how deep a spirit of wonder and perplexit...    EAP   \n",
       "24     id01704  These bizarre attempts at explanation were fol...    EAP   \n",
       "25     id10125  For many prodigies and signs had taken place, ...    EAP   \n",
       "26     id02448  All that as yet can fairly be said to be known...    EAP   \n",
       "27     id23451  I seemed to be upon the verge of comprehension...    EAP   \n",
       "28     id27907  Our compasses, depth gauges, and other delicat...    HPL   \n",
       "29     id08121  This the young warriors took back with them to...    HPL   \n",
       "...        ...                                                ...    ...   \n",
       "19549  id20955  But it was not so; I was the same in strength,...    MWS   \n",
       "19550  id01270  He then took the book himself, and read me a c...    EAP   \n",
       "19551  id22290  \"Adolphe Le Bon, clerk to Mignaud et Fils, dep...    EAP   \n",
       "19552  id20272  But of the character of his remarks at the per...    EAP   \n",
       "19553  id18082  He notes every variation of face as the play p...    EAP   \n",
       "19554  id07976  They admitted they had been drunk, but both vo...    HPL   \n",
       "19555  id26741  The rays of the newly risen sun poured in upon...    EAP   \n",
       "19556  id26698  To the north on the craggy precipice a few pac...    EAP   \n",
       "19557  id22265  The frauds of the banks of course I couldn't h...    EAP   \n",
       "19558  id14778  He was attired, as I had expected, in a costum...    EAP   \n",
       "19559  id18823  When a fumbling came in the nearer casements h...    HPL   \n",
       "19560  id00893  But then there is the tone laconic, or curt, w...    EAP   \n",
       "19561  id08678  Average people in society and business New Eng...    HPL   \n",
       "19562  id10857  The modes and sources of this kind of error ar...    EAP   \n",
       "19563  id10563  Yet from whom has not that rude hand rent away...    MWS   \n",
       "19564  id11752  Almighty God no, no They heard they suspected ...    EAP   \n",
       "19565  id26214  I hope you have not been so foolish as to take...    EAP   \n",
       "19566  id00832  These reflections made our legislators pause, ...    MWS   \n",
       "19567  id04187  Because there were some considerations of deep...    EAP   \n",
       "19568  id22378  Before going in we walked up the street, turne...    EAP   \n",
       "19569  id26790  Once my fancy was soothed with dreams of virtu...    MWS   \n",
       "19570  id14263  Nay, you may have met with another whom you ma...    MWS   \n",
       "19571  id14420  My watch was still going, and told me that the...    HPL   \n",
       "19572  id03325  But these and other difficulties attending res...    EAP   \n",
       "19573  id07567  Stress of weather drove us up the Adriatic Gul...    MWS   \n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP   \n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP   \n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP   \n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP   \n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "0      process however afforded means ascertaining di...  \n",
       "1             never occurred fumbling might mere mistake  \n",
       "2      left hand gold snuff box capered hill cutting ...  \n",
       "3      lovely spring looked Windsor Terrace sixteen f...  \n",
       "4      Finding nothing else even gold Superintendent ...  \n",
       "5      youth passed solitude best years spent gentle ...  \n",
       "6      astronomer perhaps point took refuge suggestio...  \n",
       "7                            surcingle hung ribands body  \n",
       "8      knew could say stereotomy without brought thin...  \n",
       "9      confess neither structure languages code gover...  \n",
       "10     shall find feel injuries shall learn dread rev...  \n",
       "11                             barricaded present secure  \n",
       "12     Herbert West needed fresh bodies life work rea...  \n",
       "13     farm like grounds extended back deeply hill al...  \n",
       "14                              glance show fallacy idea  \n",
       "15     escaped must commence destructive almost endle...  \n",
       "16     speeches gave course interpretation fancying d...  \n",
       "17     native sprightliness needed undue excitement p...  \n",
       "18     even went far speak slightly hectic cough one ...  \n",
       "19     facial aspect remarkable maturity though share...  \n",
       "20     net work permanently fastened hoop attached se...  \n",
       "21     sounds hideous held vibrations suggesting noth...  \n",
       "22     every hand wilderness balconies verandas minar...  \n",
       "23     deep spirit wonder perplexity wont regard remo...  \n",
       "24     bizarre attempts explanation followed others e...  \n",
       "25     many prodigies signs taken place far wide sea ...  \n",
       "26     yet fairly said known Pure gold made readily l...  \n",
       "27     seemed upon verge comprehension without power ...  \n",
       "28     compasses depth gauges delicate instruments ru...  \n",
       "29     young warriors took back Sarnath symbol conque...  \n",
       "...                                                  ...  \n",
       "19549  strength earnest craving sympathy yearning act...  \n",
       "19550                       took book read chapter aloud  \n",
       "19551  Adolphe Le Bon clerk Mignaud et Fils deposes d...  \n",
       "19552  character remarks periods question example bes...  \n",
       "19553  notes every variation face play progresses gat...  \n",
       "19554  admitted drunk vowed seen crazily dressed trio...  \n",
       "19555  rays newly risen sun poured upon whole windows...  \n",
       "19556  north craggy precipice paces verge sprang magn...  \n",
       "19557                           frauds banks course help  \n",
       "19558  attired expected costume altogether similar we...  \n",
       "19559  fumbling came nearer casements crept around we...  \n",
       "19560             tone laconic curt lately come much use  \n",
       "19561  Average people society business New England tr...  \n",
       "19562  modes sources kind error well typified contemp...  \n",
       "19563            Yet rude hand rent away dear connection  \n",
       "19564  Almighty God heard suspected knew making mocke...  \n",
       "19565  hope foolish take offence little brusquerie mi...  \n",
       "19566  reflections made legislators pause could decid...  \n",
       "19567                considerations deep interest beyond  \n",
       "19568  going walked street turned alley turning passe...  \n",
       "19569         fancy soothed dreams virtue fame enjoyment  \n",
       "19570  Nay may met another may love considering bound...  \n",
       "19571              watch still going told hour past noon  \n",
       "19572  difficulties attending respiration means great...  \n",
       "19573  Stress weather drove us Adriatic Gulph vessel ...  \n",
       "19574  could fancied looked eminent landscape painter...  \n",
       "19575                       lids clenched together spasm  \n",
       "19576  Mais il faut agir say Frenchman never faints o...  \n",
       "19577          item news like strikes us coolly received  \n",
       "19578  laid gnarled claw shoulder seemed shaking alto...  \n",
       "\n",
       "[19579 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_preprocessed']=df['text'].apply(preprocess)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:11:13.256421Z",
     "start_time": "2019-02-04T16:11:13.249763Z"
    }
   },
   "source": [
    "## Now we have to remove the empty processed text rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:14:23.468978Z",
     "start_time": "2019-02-04T16:14:23.442894Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing null/empty preprocessed texts from data, size of dataframe is (19579, 4)\n",
      "After removing null/empty preprocessed texts from data, size of dataframe is (19572, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Before removing null/empty preprocessed texts from data, size of dataframe is {}'.format(df.shape))\n",
    "df=df.loc[~df['text_preprocessed'].isnull()]\n",
    "df=df.loc[df['text_preprocessed']!='']\n",
    "print('After removing null/empty preprocessed texts from data, size of dataframe is {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:14:56.576416Z",
     "start_time": "2019-02-04T16:14:56.568563Z"
    }
   },
   "source": [
    "#### We saw seven records were removed which were either null or empty after the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:15:39.357733Z",
     "start_time": "2019-02-04T16:15:39.325666Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19572 entries, 0 to 19578\n",
      "Data columns (total 4 columns):\n",
      "id                   19572 non-null object\n",
      "text                 19572 non-null object\n",
      "author               19572 non-null object\n",
      "text_preprocessed    19572 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 764.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of unique labels : 3 \n",
      " Authors are : EAP    7895\n",
      "MWS    6043\n",
      "HPL    5634\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "texts=df['text_preprocessed'].values\n",
    "labels=df['author'].values\n",
    "data = list(labels + '\\t' + texts)\n",
    "print('Total count of unique labels : {} \\n Authors are : {}'.format(len(set(labels)),df['author'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:16:11.095980Z",
     "start_time": "2019-02-04T16:16:10.946077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tf-Idf vectorizer with different params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(texts)\n",
    "X_train_tfidf =  tfidf_vect.transform(X_train)\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(texts)\n",
    "X_train_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "X_test_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(texts)\n",
    "X_train_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train) \n",
    "X_test_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to generate accuracy dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try Naive-Bayes classifier first \n",
    "\n",
    "Implementing a naive bayes model using sklearn implementation with different features\n",
    "\n",
    "Naive Bayes is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. A Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature here ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, WordLevel TF-IDF: 0.7957099080694586\n",
      "Naive Bayes,  N-Gram Vectors: 0.5715015321756894\n",
      "Naive Bayes,CharLevel Vectors: 0.7017364657814096\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print(\"Naive Bayes, WordLevel TF-IDF: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\n",
    "print(\"Naive Bayes,  N-Gram Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\n",
    "print(\"Naive Bayes,CharLevel Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will be trying out linear classifiers with all three types of tf-idf vectorizers\n",
    "\n",
    "Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic/sigmoid function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, WordLevel TF-IDF: 0.7916241062308478\n",
      "Logistic Regression, N-Gram Vectors: 0.5704800817160368\n",
      "Logistic Regression, CharLevel Vectors: 0.7328907048008172\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print (\"Logistic Regression, WordLevel TF-IDF: \"+ str(accuracy))\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train_tfidf_ngram, y_train, X_test_tfidf_ngram)\n",
    "print(\"Logistic Regression, N-Gram Vectors: \"+ str(accuracy))\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train_tfidf_ngram_chars, y_train, X_test_tfidf_ngram_chars)\n",
    "print(\"Logistic Regression, CharLevel Vectors: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try SVC now\n",
    "\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm which can be used for both \n",
    "classification or regression challenges. The model extracts a best possible hyper-plane / line that segregates the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors: 0.4187946884576098\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print(\"SVM, N-Gram Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest \n",
    "Random Forest models are a type of ensemble models, particularly bagging models. They are part of the tree based model family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, WordLevel TF-IDF: 0.6726251276813074\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print(\"Random Forest, WordLevel TF-IDF: {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
