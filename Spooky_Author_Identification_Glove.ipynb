{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:42:45.521946Z",
     "start_time": "2019-02-17T20:42:42.570404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glove import Corpus, Glove\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import datetime,time\n",
    "from flashtext.keyword import KeywordProcessor\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from flashtext.keyword import KeywordProcessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# libraries for dataset preparation, feature engineering, model training \n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "#from utils.language_models import WordVectorEmbedding\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "#import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import spooky author data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:42:47.004370Z",
     "start_time": "2019-02-17T20:42:46.947905Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv',encoding='utf-8')\n",
    "df.head()\n",
    "sen=df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T20:21:03.575071Z",
     "start_time": "2019-02-12T20:21:03.570253Z"
    }
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:43:47.243392Z",
     "start_time": "2019-02-17T20:43:47.238218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function for removing regex\n",
    "def regex_filtering(text):\n",
    "        if text:\n",
    "            #removing all email metadata fix it for email terms only\n",
    "            text=re.sub(r\"^(sender|to|copy|from|sent|subject|date|cc|e|von|datum|an|importance|bcc):.*$\",\" \",text,flags=re.M)\n",
    "            #removing all mail ids\n",
    "            text=re.sub(r\"\\S*@\\S*\\s?\",\" \",text)\n",
    "            #removing all links\n",
    "            text=re.sub(r\"(((https?|ftp|file):\\/\\/)|www\\\\.)\\\\S+\", ' ', text, flags=re.MULTILINE)\n",
    "            text=re.sub(r\"\\w*\\.\\w{1,4}\", '', text, flags=re.MULTILINE)\n",
    "            #removing all non word character\n",
    "            text=re.sub(r\"([^a-zA-Z0-9\\\\u00C0-\\\\u00FF@]|[Ã£Ã¢])+\",' ',text)\n",
    "            #removing words with numbers \n",
    "            text=re.sub(r'\\w*\\d\\w*', ' ', text)\n",
    "            #removing single characters\n",
    "            text=re.sub(r'\\b\\S{1}\\s+',' ',text)\n",
    "            #removing words with repeating characters\n",
    "            text=re.sub(r'\\b(\\w)\\1{1,}\\s+',' ',text)\n",
    "            #removing punkt\n",
    "            text = text.translate(str.maketrans('','',string.punctuation))\n",
    "            #removing extra whitespace\n",
    "            text=re.sub(r\"\\s\\s+\",' ',text)\n",
    "            #removing repeating words\n",
    "            text=re.sub(r\"(\\w+\\s+)\\1{1,}\",' ',text)\n",
    "            #removing whitespaces\n",
    "            text=text.strip()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:43:48.069838Z",
     "start_time": "2019-02-17T20:43:48.066040Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize Terms and remove stopwords\n",
    "def tokenize_term(x):\n",
    "        predefined_stopwords='horror perfectly'\n",
    "        english_stopwords=stopwords.words(\"english\")\n",
    "        stopwords_list=(list(predefined_stopwords.split(' '))+english_stopwords)         \n",
    "        keyword_processor_stopwords = KeywordProcessor()\n",
    "        for each in stopwords_list:\n",
    "            keyword_processor_stopwords.add_keyword(each,' ')   \n",
    "        sentence=keyword_processor_stopwords.replace_keywords(x)\n",
    "        return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:43:49.302456Z",
     "start_time": "2019-02-17T20:43:49.299190Z"
    }
   },
   "outputs": [],
   "source": [
    "#Combined function\n",
    "def preprocess(text):\n",
    "    return regex_filtering(tokenize_term(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:43:21.708468Z",
     "start_time": "2019-02-17T20:43:11.611739Z"
    }
   },
   "outputs": [],
   "source": [
    "#Apply function preprocess and save result as new column\n",
    "df['text_preprocessed']=df['text'].apply(preprocess)\n",
    "texts=df['text_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:45:13.400874Z",
     "start_time": "2019-02-17T20:45:13.390979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                   text_preprocessed  \n",
       "0  process however afforded means ascertaining di...  \n",
       "1         never occurred fumbling might mere mistake  \n",
       "2  left hand gold snuff box capered hill cutting ...  \n",
       "3  lovely spring looked Windsor Terrace sixteen f...  \n",
       "4  Finding nothing else even gold Superintendent ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:47:46.974337Z",
     "start_time": "2019-02-17T20:47:41.945445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "      <td>process however afford mean ascertain dimensio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "      <td>never occur fumble might mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "      <td>leave hand gold snuff box caper hill cut manne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "      <td>lovely spring look Windsor Terrace sixteen fer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  process however afforded means ascertaining di...   \n",
       "1         never occurred fumbling might mere mistake   \n",
       "2  left hand gold snuff box capered hill cutting ...   \n",
       "3  lovely spring looked Windsor Terrace sixteen f...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  process however afford mean ascertain dimensio...  \n",
       "1              never occur fumble might mere mistake  \n",
       "2  leave hand gold snuff box caper hill cut manne...  \n",
       "3  lovely spring look Windsor Terrace sixteen fer...  \n",
       "4  Finding nothing else even gold Superintendent ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatize different forms of words\n",
    "def lemmatize_doc(dataframe):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer() \n",
    "    lemmatized = [[wordnet_lemmatizer.lemmatize(word,pos='v') for word in word_tokenize(s)]\n",
    "                  for s in dataframe['text_preprocessed']]\n",
    "    return lemmatized\n",
    "lemma_data=lemmatize_doc(df)\n",
    "df['text_lemmatized']=[\" \".join(i) for i in lemma_data]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:48:58.993887Z",
     "start_time": "2019-02-17T20:48:58.989211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/spooky_author_glove_embedding_model_2019-02-17_50_epoch.model\n",
      "model/spooky_author_glove_embedding_model_2019-02-17_50_epoch.txt\n"
     ]
    }
   ],
   "source": [
    "###Saving models with timestamp\n",
    "import datetime,time\n",
    "\n",
    "path=\"model/\"\n",
    "epochs=50\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d')+\"_\"\n",
    "model_file_path =  path + \"spooky_author_glove_embedding_model_\"+str(st) + str(epochs) + \"_epoch.model\"\n",
    "glove_vectors_path = path + \"spooky_author_glove_embedding_model_\" + str(st)+ str(epochs) + \"_epoch.txt\"\n",
    "#glove_to_w2v_path = path + \"spooky_author_glove_embedding_model_\" +str(st)  + \"_glove_to_word2vec.txt\"\n",
    "print (model_file_path)\n",
    "print (glove_vectors_path)\n",
    "#print(glove_to_w2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper-parameters for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:49:04.106805Z",
     "start_time": "2019-02-17T20:49:04.103321Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Parameters for glove model\n",
    "window = 5         ##### Contect window of every sentence it has to take\n",
    "no_components=50  ##### No.of Dimiensions or size of vectors\n",
    "learning_rate=0.05 ##### Learning rate or alpha\n",
    "no_threads=84      ##### Multiprocessing ( specify the cores)\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train glove embedding and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:30.720512Z",
     "start_time": "2019-02-17T20:50:24.579493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove embedding model trained successfully. \n",
      "Model saved in the following path : model/spooky_author_glove_embedding_model_2019-02-17_50_epoch.model\n"
     ]
    }
   ],
   "source": [
    "# creating a corpus object\n",
    "corpus = Corpus() \n",
    "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lemma_data, window=window)\n",
    "\n",
    "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
    "#We can set the learning rate as it uses Gradient Descent and number of components\n",
    "glove = Glove(no_components=no_components, learning_rate=learning_rate)\n",
    " \n",
    "glove.fit(corpus.matrix, epochs=epochs, no_threads=no_threads, verbose=False)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save(model_file_path)\n",
    "print('Glove embedding model trained successfully. \\nModel saved in the following path : {}'.format(model_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model in vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:53:21.390052Z",
     "start_time": "2019-02-17T20:53:20.429568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model in vector format\n",
    "word_vectors = glove.word_vectors\n",
    "\n",
    "# Writing a vector file \n",
    "#Sample word : word1 0.2178995609092781 -0.3523739278544217 -0.14607002613618192 -0.0019162911041566608 \n",
    "\n",
    "words = list(glove.dictionary)\n",
    "word_vectors_for_words  = word_vectors.tolist()\n",
    "glove_vectors = [m + \" \" + str(\" \".join(str(item) for item in n)) for m,n in zip(words,word_vectors_for_words)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:53:23.731833Z",
     "start_time": "2019-02-17T20:53:23.675085Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(glove_vectors_path,\"w+\") as fp:\n",
    "    for line in glove_vectors:\n",
    "        fp.write(str(line))\n",
    "        fp.write(\"\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:54:38.288213Z",
     "start_time": "2019-02-17T20:54:38.277792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "      <td>process however afford mean ascertain dimensio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "      <td>never occur fumble might mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "      <td>leave hand gold snuff box caper hill cut manne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "      <td>lovely spring look Windsor Terrace sixteen fer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  process however afforded means ascertaining di...   \n",
       "1         never occurred fumbling might mere mistake   \n",
       "2  left hand gold snuff box capered hill cutting ...   \n",
       "3  lovely spring looked Windsor Terrace sixteen f...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  process however afford mean ascertain dimensio...  \n",
       "1              never occur fumble might mere mistake  \n",
       "2  leave hand gold snuff box caper hill cut manne...  \n",
       "3  lovely spring look Windsor Terrace sixteen fer...  \n",
       "4  Finding nothing else even gold Superintendent ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove null rows present after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:54:42.485904Z",
     "start_time": "2019-02-17T20:54:42.476502Z"
    }
   },
   "outputs": [],
   "source": [
    "filter_=df['text_lemmatized'].apply(lambda x:True if not x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:54:43.513750Z",
     "start_time": "2019-02-17T20:54:43.494256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing empty strings 6\n",
      "After removing empty strings 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing empty strings {}\".format(filter_.sum()))\n",
    "df=df[~filter_]\n",
    "filter_=df['text_lemmatized'].apply(lambda x:True if not x else False)\n",
    "print(\"After removing empty strings {}\".format(filter_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:55:28.670558Z",
     "start_time": "2019-02-17T20:55:28.662762Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df[~filter_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find average vector of each sentence from the trained glove vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:56:31.811739Z",
     "start_time": "2019-02-17T20:56:31.807367Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize(list_of_strings,vector_size):\n",
    "    global model\n",
    "    array_len=len(list_of_strings)\n",
    "    vector=np.array([0]*vector_size,dtype='float64')\n",
    "    for text in list_of_strings:\n",
    "        try:\n",
    "            vector+=word_vectors[glove.dictionary[text]]\n",
    "        except KeyError:\n",
    "            vector+=np.array([0]*vector_size,dtype='float64')\n",
    "    #Vectorize avrg\n",
    "    vector_to_return=vector/array_len\n",
    "    return vector_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:56:44.327737Z",
     "start_time": "2019-02-17T20:56:34.649072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>vectorized_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "      <td>process however afford mean ascertain dimensio...</td>\n",
       "      <td>[-0.001400567117661585, -0.001340283304660479,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "      <td>never occur fumble might mere mistake</td>\n",
       "      <td>[-0.0009347250675251107, -0.000693032438372496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "      <td>leave hand gold snuff box caper hill cut manne...</td>\n",
       "      <td>[-0.002165417531272407, -0.001456710128963926,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "      <td>lovely spring look Windsor Terrace sixteen fer...</td>\n",
       "      <td>[-0.0013816478842009468, -0.000885050645054020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>[-0.0015449137596513203, -0.001517233931621229...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  process however afforded means ascertaining di...   \n",
       "1         never occurred fumbling might mere mistake   \n",
       "2  left hand gold snuff box capered hill cutting ...   \n",
       "3  lovely spring looked Windsor Terrace sixteen f...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  process however afford mean ascertain dimensio...   \n",
       "1              never occur fumble might mere mistake   \n",
       "2  leave hand gold snuff box caper hill cut manne...   \n",
       "3  lovely spring look Windsor Terrace sixteen fer...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                vectorized_sentences  \n",
       "0  [-0.001400567117661585, -0.001340283304660479,...  \n",
       "1  [-0.0009347250675251107, -0.000693032438372496...  \n",
       "2  [-0.002165417531272407, -0.001456710128963926,...  \n",
       "3  [-0.0013816478842009468, -0.000885050645054020...  \n",
       "4  [-0.0015449137596513203, -0.001517233931621229...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_sentences=[vectorize(i,50) for i in df['text_lemmatized']]\n",
    "df['vectorized_sentences']=vectorized_sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast average sentence vectors to pandas series for easier processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:57:42.766320Z",
     "start_time": "2019-02-17T20:57:39.158757Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit vectors\n",
    "X_vec=df['vectorized_sentences'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:57:52.989220Z",
     "start_time": "2019-02-17T20:57:52.966450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.002509</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-2.750992e-04</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.001706</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.000693</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-1.808857e-04</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.001358</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>-0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002165</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>3.811707e-04</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>-0.001794</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.002887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001382</td>\n",
       "      <td>-0.000885</td>\n",
       "      <td>-0.002176</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-9.933850e-08</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.001191</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>-0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001545</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-8.625801e-04</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.001590</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>-0.001362</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>-0.004685</td>\n",
       "      <td>-0.002941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5             6   \\\n",
       "0 -0.001401 -0.001340 -0.002509  0.001066 -0.001001 -0.000061 -2.750992e-04   \n",
       "1 -0.000935 -0.000693 -0.001614  0.000486 -0.000376  0.000378 -1.808857e-04   \n",
       "2 -0.002165 -0.001457 -0.003180  0.001160 -0.001349 -0.000094  3.811707e-04   \n",
       "3 -0.001382 -0.000885 -0.002176  0.000920 -0.000709 -0.000259 -9.933850e-08   \n",
       "4 -0.001545 -0.001517 -0.003125  0.001515 -0.001025 -0.000484 -8.625801e-04   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0  0.004114  0.000239 -0.000145  ... -0.000506 -0.001195 -0.001706  0.001332   \n",
       "1  0.002598 -0.000266  0.000114  ... -0.000360 -0.000422 -0.001358  0.000485   \n",
       "2  0.005479 -0.000086 -0.000541  ... -0.000505 -0.001794 -0.002524  0.001929   \n",
       "3  0.003671  0.000306 -0.000263  ... -0.000190 -0.001191 -0.001608  0.001279   \n",
       "4  0.004846  0.001085  0.000059  ... -0.000441 -0.001590 -0.001628  0.001658   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0  0.000913  0.001430 -0.001371 -0.000020 -0.003701 -0.002175  \n",
       "1  0.000522  0.000843 -0.001231  0.000085 -0.002565 -0.001393  \n",
       "2  0.001143  0.001242 -0.001695 -0.000470 -0.004260 -0.002887  \n",
       "3  0.000768  0.000949 -0.001063 -0.000129 -0.002944 -0.002089  \n",
       "4  0.001080  0.002108 -0.001362  0.000179 -0.004685 -0.002941  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Label-encoder to transform author class labels to machine understandable number inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:59:29.676464Z",
     "start_time": "2019-02-17T20:59:29.651290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>vectorized_sentences</th>\n",
       "      <th>author_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>process however afforded means ascertaining di...</td>\n",
       "      <td>process however afford mean ascertain dimensio...</td>\n",
       "      <td>[-0.001400567117661585, -0.001340283304660479,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>never occurred fumbling might mere mistake</td>\n",
       "      <td>never occur fumble might mere mistake</td>\n",
       "      <td>[-0.0009347250675251107, -0.000693032438372496...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>left hand gold snuff box capered hill cutting ...</td>\n",
       "      <td>leave hand gold snuff box caper hill cut manne...</td>\n",
       "      <td>[-0.002165417531272407, -0.001456710128963926,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>lovely spring looked Windsor Terrace sixteen f...</td>\n",
       "      <td>lovely spring look Windsor Terrace sixteen fer...</td>\n",
       "      <td>[-0.0013816478842009468, -0.000885050645054020...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>Finding nothing else even gold Superintendent ...</td>\n",
       "      <td>[-0.0015449137596513203, -0.001517233931621229...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  process however afforded means ascertaining di...   \n",
       "1         never occurred fumbling might mere mistake   \n",
       "2  left hand gold snuff box capered hill cutting ...   \n",
       "3  lovely spring looked Windsor Terrace sixteen f...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  process however afford mean ascertain dimensio...   \n",
       "1              never occur fumble might mere mistake   \n",
       "2  leave hand gold snuff box caper hill cut manne...   \n",
       "3  lovely spring look Windsor Terrace sixteen fer...   \n",
       "4  Finding nothing else even gold Superintendent ...   \n",
       "\n",
       "                                vectorized_sentences  author_encoded  \n",
       "0  [-0.001400567117661585, -0.001340283304660479,...               0  \n",
       "1  [-0.0009347250675251107, -0.000693032438372496...               1  \n",
       "2  [-0.002165417531272407, -0.001456710128963926,...               0  \n",
       "3  [-0.0013816478842009468, -0.000885050645054020...               2  \n",
       "4  [-0.0015449137596513203, -0.001517233931621229...               1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['author_encoded']=le.fit_transform(df['author'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:59:46.606735Z",
     "start_time": "2019-02-17T20:59:46.574391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19573 entries, 0 to 19578\n",
      "Data columns (total 7 columns):\n",
      "id                      19573 non-null object\n",
      "text                    19573 non-null object\n",
      "author                  19573 non-null object\n",
      "text_preprocessed       19573 non-null object\n",
      "text_lemmatized         19573 non-null object\n",
      "vectorized_sentences    19573 non-null object\n",
      "author_encoded          19573 non-null int64\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Let's check the dataframe information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to feed into different ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:02:13.028871Z",
     "start_time": "2019-02-17T21:02:13.026404Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change to vector\n",
    "texts=X_vec\n",
    "labels=df['author_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:02:28.854371Z",
     "start_time": "2019-02-17T21:02:28.841625Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to generate accuracy of different models on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:03:08.246370Z",
     "start_time": "2019-02-17T21:03:08.242280Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:03:18.692317Z",
     "start_time": "2019-02-17T21:03:18.689066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train 17615 and X_test 1958\n",
      "Shape of y_train 17615 and y_test 1958\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train {} and X_test {}'.format(len(X_train),len(X_test)))\n",
    "print('Shape of y_train {} and y_test {}'.format(len(y_train),len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:03:29.840428Z",
     "start_time": "2019-02-17T21:03:28.639442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest classifier, with glove embeddings: 0.3769152196118488\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), X_train, y_train, X_test)\n",
    "print (\"Accuracy Random Forest classifier, with glove embeddings: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:04:16.942669Z",
     "start_time": "2019-02-17T21:03:39.696283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC classifier, with glove embeddings: 0.41419816138917265\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), X_train, y_train, X_test)\n",
    "print (\"Accuracy of SVC classifier, with glove embeddings: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T21:05:00.133957Z",
     "start_time": "2019-02-17T21:04:59.920427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier, with glove embeddings: 0.41419816138917265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), X_train, y_train, X_test)\n",
    "print (\"Accuracy of Logistic Regression classifier, with glove embeddings: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
